{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pathlib import Path #used for handling path. Instead of using path as strings it converts them into path objects which is usefull in neural networks\n",
    "from tensorflow.keras.utils import to_categorical #used to convert categorical labels into categorical vectors \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Dataset\n",
    "\n",
    "parent_dir = Path(r\"images\")\n",
    "\n",
    "actual_img_paths = [p for child_dir in ['yes','no']\n",
    "                    if (parent_dir/child_dir).is_dir()\n",
    "                    for p in (parent_dir/child_dir).glob('*')\n",
    "                    if not p.name.startswith('.')]\n",
    "\n",
    "labels = [p.parent.name for p in actual_img_paths]\n",
    "\n",
    "df = pd.DataFrame({'filepath' : actual_img_paths, 'label' : labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\yes\\Y1.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\yes\\Y10.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\yes\\Y100.JPG</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\yes\\Y101.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\yes\\Y102.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>images\\no\\No18.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>images\\no\\No19.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>images\\no\\No20.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>images\\no\\No21.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>images\\no\\No22.jpg</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filepath label\n",
       "0      images\\yes\\Y1.jpg   yes\n",
       "1     images\\yes\\Y10.jpg   yes\n",
       "2    images\\yes\\Y100.JPG   yes\n",
       "3    images\\yes\\Y101.jpg   yes\n",
       "4    images\\yes\\Y102.jpg   yes\n",
       "..                   ...   ...\n",
       "248   images\\no\\No18.jpg    no\n",
       "249   images\\no\\No19.jpg    no\n",
       "250   images\\no\\No20.jpg    no\n",
       "251   images\\no\\No21.jpg    no\n",
       "252   images\\no\\No22.jpg    no\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['filepath'], df['label'], test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 51)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size, X_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizes the input image to 224x224\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import cv2\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = preprocess_input(img) #preprocesses the images (normalizes it so that it is accepted by the model)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_images = [load_and_preprocess_image(img_path) for img_path in X_train]\n",
    "\n",
    "X_train_images = np.array([img for img in X_train_images if img is not None]) # to remove any failed loads\n",
    "\n",
    "X_test_images = [load_and_preprocess_image(img_path) for img_path in X_test]\n",
    "\n",
    "X_test_images = np.array([img for img in X_test_images if img is not None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode the labels for format compatibility\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(Y_train)\n",
    "y_test_encoded = le.fit_transform(Y_test)\n",
    "\n",
    "X_train_shuffled, Y_train_shuffled = shuffle(X_train_images, y_train_encoded, random_state = 42)\n",
    "\n",
    "y_train_shuffled_encoded = to_categorical(Y_train_shuffled)\n",
    "y_test_encoded = to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "demo_datagen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    width_shift_range = 0.15,\n",
    "    height_shift_range = 0.15,\n",
    "    shear_range = 0.15,\n",
    "    zoom_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = False,\n",
    "    fill_mode = 'nearest',\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    channel_shift_range = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
